{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e43916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"kaggle/input/playground-series-s5e11/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4e53453",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     30\u001b[39m gp = SymbolicClassifier(\n\u001b[32m     31\u001b[39m     population_size=\u001b[32m2000\u001b[39m,\n\u001b[32m     32\u001b[39m     generations=\u001b[32m20\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     41\u001b[39m     random_state=\u001b[32m42\u001b[39m\n\u001b[32m     42\u001b[39m )\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# ---- 5. Fit and evaluate ----\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[43mgp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# Patch missing attribute for sklearn >=1.3 compatibility\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(gp, \u001b[33m\"\u001b[39m\u001b[33mn_features_in_\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Blanc\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\playground-lwZmZsxv-py3.12\\Lib\\site-packages\\gplearn\\genetic.py:476\u001b[39m, in \u001b[36mBaseSymbolic.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    472\u001b[39m n_jobs, n_programs, starts = _partition_estimators(\n\u001b[32m    473\u001b[39m     \u001b[38;5;28mself\u001b[39m.population_size, \u001b[38;5;28mself\u001b[39m.n_jobs)\n\u001b[32m    474\u001b[39m seeds = random_state.randint(MAX_INT, size=\u001b[38;5;28mself\u001b[39m.population_size)\n\u001b[32m--> \u001b[39m\u001b[32m476\u001b[39m population = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_evolve\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_programs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mparents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m                              \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m                              \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[38;5;66;03m# Reduce, maintaining order across different n_jobs\u001b[39;00m\n\u001b[32m    488\u001b[39m population = \u001b[38;5;28mlist\u001b[39m(itertools.chain.from_iterable(population))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Blanc\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\playground-lwZmZsxv-py3.12\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Blanc\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\playground-lwZmZsxv-py3.12\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Blanc\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\playground-lwZmZsxv-py3.12\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Ensure target is numeric (GP needs numeric y)\n",
    "df[\"loan_paid_back\"] = pd.to_numeric(df[\"loan_paid_back\"], errors=\"coerce\")\n",
    "\n",
    "X = df.drop(columns=[\"loan_paid_back\"])\n",
    "y = df[\"loan_paid_back\"]\n",
    "\n",
    "# If you still have categorical columns, encode or drop them:\n",
    "X = X.select_dtypes(include=[\"int64\", \"float64\"]).copy()\n",
    "\n",
    "# ---- 2. Patch gplearn for new scikit-learn versions ----\n",
    "import gplearn.genetic\n",
    "from sklearn.utils.validation import check_X_y\n",
    "\n",
    "def _validate_data(self, X, y, y_numeric=True):\n",
    "    X, y = check_X_y(X, y, y_numeric=y_numeric)\n",
    "    return X, y\n",
    "\n",
    "gplearn.genetic.BaseSymbolic._validate_data = _validate_data\n",
    "\n",
    "# ---- 3. Split data ----\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ---- 4. Define Symbolic Regressor ----\n",
    "from gplearn.genetic import SymbolicClassifier\n",
    "\n",
    "gp = SymbolicClassifier(\n",
    "    population_size=2000,\n",
    "    generations=20,\n",
    "    tournament_size=20,\n",
    "    stopping_criteria=0.01,\n",
    "    const_range=(-1, 1),\n",
    "    init_depth=(2, 6),\n",
    "    function_set=('add', 'sub', 'mul', 'div', 'sqrt', 'log', 'abs', 'neg', 'sin', 'cos', 'tan'),\n",
    "    parsimony_coefficient=0.001,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ---- 5. Fit and evaluate ----\n",
    "gp.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Patch missing attribute for sklearn >=1.3 compatibility\n",
    "if not hasattr(gp, \"n_features_in_\"):\n",
    "    gp.n_features_in_ = X_train.shape[1]\n",
    "    \n",
    "y_pred = gp.predict(X_test)\n",
    "print(\"R2:\", r2_score(y_test, y_pred))\n",
    "print(\"Best expression:\", gp._program)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e88fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", (y_pred == y_test).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7f54bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gplearn.genetic import SymbolicTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "gp_features = SymbolicTransformer(\n",
    "    generations=1,\n",
    "    population_size=3000,\n",
    "    hall_of_fame=100,\n",
    "    n_components=15,   # number of new features to keep\n",
    "    function_set=('add', 'sub', 'mul', 'div', 'sqrt', 'log', 'sin', 'cos', 'abs'),\n",
    "    parsimony_coefficient=0.0005,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- Fit the transformer on training data ---\n",
    "gp_features.fit(X_train, y_train)\n",
    "\n",
    "# Patch missing attribute for sklearn >=1.3 compatibility\n",
    "if not hasattr(gp_features, \"n_features_in_\"):\n",
    "    gp_features.n_features_in_ = X_train.shape[1]\n",
    "\n",
    "# --- Transform data to get new columns ---\n",
    "X_train_new = gp_features.transform(X_train)\n",
    "X_test_new = gp_features.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0751107",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, program in enumerate(gp_features._best_programs[:10]):\n",
    "    print(f\"GP_{i}: {program}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground-lwZmZsxv-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
