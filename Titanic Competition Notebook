{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"isSourceIdPinned":false,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-23T08:22:56.049811Z","iopub.execute_input":"2025-09-23T08:22:56.050177Z","iopub.status.idle":"2025-09-23T08:22:56.056799Z","shell.execute_reply.started":"2025-09-23T08:22:56.050150Z","shell.execute_reply":"2025-09-23T08:22:56.055929Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}],"execution_count":78},{"cell_type":"markdown","source":"## Import modules","metadata":{}},{"cell_type":"code","source":"# full\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nimport warnings\n\n# partial\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\n\n# warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T08:22:56.058250Z","iopub.execute_input":"2025-09-23T08:22:56.058563Z","iopub.status.idle":"2025-09-23T08:22:56.078745Z","shell.execute_reply.started":"2025-09-23T08:22:56.058536Z","shell.execute_reply":"2025-09-23T08:22:56.077817Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ndf[\"Sex\"] = df[\"Sex\"].map({\"male\":1, \"female\":0})\ndf[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].mean().round(0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T08:22:56.079896Z","iopub.execute_input":"2025-09-23T08:22:56.080197Z","iopub.status.idle":"2025-09-23T08:22:56.101799Z","shell.execute_reply.started":"2025-09-23T08:22:56.080174Z","shell.execute_reply":"2025-09-23T08:22:56.100935Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"print(df.info())\ndf.describe(include='all')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T08:22:56.103243Z","iopub.execute_input":"2025-09-23T08:22:56.103489Z","iopub.status.idle":"2025-09-23T08:22:56.152851Z","shell.execute_reply.started":"2025-09-23T08:22:56.103470Z","shell.execute_reply":"2025-09-23T08:22:56.151987Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    int64  \n 5   Age          891 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(6), object(4)\nmemory usage: 83.7+ KB\nNone\n","output_type":"stream"},{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"        PassengerId    Survived      Pclass                     Name  \\\ncount    891.000000  891.000000  891.000000                      891   \nunique          NaN         NaN         NaN                      891   \ntop             NaN         NaN         NaN  Braund, Mr. Owen Harris   \nfreq            NaN         NaN         NaN                        1   \nmean     446.000000    0.383838    2.308642                      NaN   \nstd      257.353842    0.486592    0.836071                      NaN   \nmin        1.000000    0.000000    1.000000                      NaN   \n25%      223.500000    0.000000    2.000000                      NaN   \n50%      446.000000    0.000000    3.000000                      NaN   \n75%      668.500000    1.000000    3.000000                      NaN   \nmax      891.000000    1.000000    3.000000                      NaN   \n\n               Sex         Age       SibSp       Parch  Ticket        Fare  \\\ncount   891.000000  891.000000  891.000000  891.000000     891  891.000000   \nunique         NaN         NaN         NaN         NaN     681         NaN   \ntop            NaN         NaN         NaN         NaN  347082         NaN   \nfreq           NaN         NaN         NaN         NaN       7         NaN   \nmean      0.647587   29.758889    0.523008    0.381594     NaN   32.204208   \nstd       0.477990   13.002570    1.102743    0.806057     NaN   49.693429   \nmin       0.000000    0.420000    0.000000    0.000000     NaN    0.000000   \n25%       0.000000   22.000000    0.000000    0.000000     NaN    7.910400   \n50%       1.000000   30.000000    0.000000    0.000000     NaN   14.454200   \n75%       1.000000   35.000000    1.000000    0.000000     NaN   31.000000   \nmax       1.000000   80.000000    8.000000    6.000000     NaN  512.329200   \n\n          Cabin Embarked  \ncount       204      889  \nunique      147        3  \ntop     B96 B98        S  \nfreq          4      644  \nmean        NaN      NaN  \nstd         NaN      NaN  \nmin         NaN      NaN  \n25%         NaN      NaN  \n50%         NaN      NaN  \n75%         NaN      NaN  \nmax         NaN      NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891</td>\n      <td>891.000000</td>\n      <td>204</td>\n      <td>889</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>891</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>681</td>\n      <td>NaN</td>\n      <td>147</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>347082</td>\n      <td>NaN</td>\n      <td>B96 B98</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>644</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>446.000000</td>\n      <td>0.383838</td>\n      <td>2.308642</td>\n      <td>NaN</td>\n      <td>0.647587</td>\n      <td>29.758889</td>\n      <td>0.523008</td>\n      <td>0.381594</td>\n      <td>NaN</td>\n      <td>32.204208</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>257.353842</td>\n      <td>0.486592</td>\n      <td>0.836071</td>\n      <td>NaN</td>\n      <td>0.477990</td>\n      <td>13.002570</td>\n      <td>1.102743</td>\n      <td>0.806057</td>\n      <td>NaN</td>\n      <td>49.693429</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.420000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>223.500000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>22.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>7.910400</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>446.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>30.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>14.454200</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>668.500000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>35.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>31.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>891.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>80.000000</td>\n      <td>8.000000</td>\n      <td>6.000000</td>\n      <td>NaN</td>\n      <td>512.329200</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":81},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import accuracy_score\n\n# ML Models\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.svm import SVR\nfrom xgboost import XGBRegressor\n\n# Fill numeric NaN with median\nnum_cols = df.select_dtypes(include=['int64','float64']).columns\ndf[num_cols] = df[num_cols].fillna(df[num_cols].median())\n\n# Fill categorical NaN with mode\ncat_cols = df.select_dtypes(include=['object']).columns\nfor col in cat_cols:\n    df[col] = df[col].fillna(df[col].mode()[0])\n\nlabel_cols = ['Name', 'Ticket', 'Cabin', 'Embarked']\nle = LabelEncoder()\nfor col in label_cols:\n    df[col] = le.fit_transform(df[col].astype(str))\n\nX = df.drop([\"Survived\", 'PassengerId', 'Embarked', \"SibSp\" , \"Parch\", \"Fare\"], axis=1)   # Features\ny = df[\"Survived\"]                                 # Target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T08:25:01.534141Z","iopub.execute_input":"2025-09-23T08:25:01.534426Z","iopub.status.idle":"2025-09-23T08:25:01.559650Z","shell.execute_reply.started":"2025-09-23T08:25:01.534406Z","shell.execute_reply":"2025-09-23T08:25:01.558554Z"}},"outputs":[],"execution_count":94},{"cell_type":"code","source":"X.columns\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T08:23:51.729701Z","iopub.execute_input":"2025-09-23T08:23:51.730060Z","iopub.status.idle":"2025-09-23T08:23:51.736188Z","shell.execute_reply.started":"2025-09-23T08:23:51.730033Z","shell.execute_reply":"2025-09-23T08:23:51.735172Z"}},"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"Index(['Pclass', 'Name', 'Sex', 'Age'], dtype='object')"},"metadata":{}}],"execution_count":86},{"cell_type":"code","source":"models = {\n    \"Linear Regression\": LinearRegression(),\n    \"Random Forest\": RandomForestRegressor(),\n    \"Gradient Boosting\": GradientBoostingRegressor(),\n    \"SVM\": SVR(),\n    \"XGBoost\": XGBRegressor()\n}\n\nresults = {}\n\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    r2 = r2_score(y_test, y_pred) * 100\n    results[name] = r2\n    print(f\"{name:20} : {r2:.2f} %\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T08:25:03.262242Z","iopub.execute_input":"2025-09-23T08:25:03.262537Z","iopub.status.idle":"2025-09-23T08:25:03.752478Z","shell.execute_reply.started":"2025-09-23T08:25:03.262514Z","shell.execute_reply":"2025-09-23T08:25:03.751860Z"}},"outputs":[{"name":"stdout","text":"Linear Regression    : 43.67 %\nRandom Forest        : 31.58 %\nGradient Boosting    : 41.13 %\nSVM                  : -6.36 %\nXGBoost              : 19.22 %\n","output_type":"stream"}],"execution_count":95}]}